colnames(x50_dummy)[7] <- "pt"
attach(x50_dummy)
View(x50_dummy)
#Multi-Linear Regression
#Where all variables x1,x2,x3,x4,x5,x6 and y are continous
#y-pt,x1-rd,x2-ad,x3-ms,x4-sc,x5-sf,x6-sn
# Exploratory Data Analysis
summary(x50_dummy)
#Find the correlation b/n Output (pt) & (rd,ad,ms,sc,sf,sn)-Scatter plot
pairs(x50_dummy)
plot(x50_dummy)
library(psych)
pairs.panels(x50_dummy)
#Correlation coefficient
cor(x50_dummy)
library(corpcor)
cor2pcor(cor(x50_dummy))
#Model bulding
mlr <- lm(pt~rd+ad+ms+sc+sf+sn ,data = x50_dummy)
summary(mlr)
install.packages("caret")
install.packages("caret")
library(caret)
pmlr <- predict(mlr)
RMSE(x50_dummy$pt,pmlr)
vif(mlr)
# Exponential Model
attach(x50_dummy)
mlr1_exp <- lm(log(pt) ~.,data = x50_dummy)
summary(mlr1_exp)
pexp <- predict(mlr1_exp)
RMSE(x50_dummy$pt,pexp)
#Logrithamic Model
attach(x50_dummy)
mlr2_log <- lm(pt ~ log(c(rd+ad+ms+sc+sf+sn)),data = x50_dummy)
summary(mlr2_log)
plog <- predict(mlr2_log)
summary(plog)
RMSE(x50_dummy$pt,plog)
# Polynomial model with 2 degree (quadratic model)
mlr2degree <- lm(log(pt) ~ (rd + I(rd*rd))+(ad + I(ad*ad))+(ms + I(ms*ms))+(sc + I(sc*sc))+(sf + I(sf*sf))+(sn + I(sn*sn)))
mlr2degree <- lm(log(pt) ~ c(rd+ad+ms+sc+sf+sn)+ I(c((rd*rd)+(ad*ad)+(ms*ms)+(sc*sc)+(sf*sf)+(sn*sn))))
summary(mlr2degree)
# It is Better to delete influential observations rather than deleting entire column which is
# costliest process
# Deletion Diagnostics for identifying influential observations
influence.measures(mlr)
library(car)
## plotting Influential measures
influenceIndexPlot(mlr,id.n=3) # index plots for infuence measures
influencePlot(mlr,id.n=3) # A user friendly representation of the above
# Regression after deleting the 50th,49th,47th observations, which is influential observation
mlr1<-lm(pt~.,data=x50_dummy[-c(50,49,47),])
summary(mlr1)
## Variance Inflation factor to check collinearity b/n variables
library(car)
library(VIF)
vif(mlr)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr2_log,id.n=2,id.cex=0.7)
qqPlot(mlr2_log,id.n = 5)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr1,id.n=2,id.cex=0.7)
qqPlot(mlr1,id.n = 5)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr,id.n=2,id.cex=0.7)
library(caret)
library(car)
pmlr <- predict(mlr)
mean(pmlr)
RMSE(cmd1$price,pmlr)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr,id.n=2,id.cex=0.7)
qqPlot(mlr,id.n = 5)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr,id.n=2,id.cex=0.7)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr,id.n=2,id.cex=0.7)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr2_log,id.n=2,id.cex=0.7)
plot(x50_dummy)
#Find the correlation b/n Output (pt) & (rd,ad,ms,sc,sf,sn)-Scatter plot
pairs(x50_dummy)
pairs.panels(x50_dummy)
claimants <- read.csv(file.choose())
View(claimants)
install.packages("VIF")
library(VIF)
attach(claimants)
fit1<-glm(ATTORNEY~CLMSEX+CLMINSUR+SEATBELT+CLMAGE+LOSS,data = claimants,family = "binomial")
summary(fit1)
# Linear regression technique can not be employed
prob1 <- predict(fit1,type="response")
# Logistic Regression
str(claimants)
logit<-glm(factor(ATTORNEY)~factor(CLMSEX)+factor(CLMINSUR)+factor(SEATBELT)+CLMAGE+LOSS,family=binomial,data = claimants)
summary(logit)
summary(fit1)
summary(logit)
logit1<-glm(ATTORNEY~factor(CLMSEX)+factor(CLMINSUR)+CLMAGE+LOSS,family=binomial,data = claimants)
summary(logit1)
exp(coef(logit1))
table(claimants$ATTORNEY)
# Confusion matrix table
prob <- predict(logit1,type=c("response"),claimants)
prob
confusion<-table(prob>0.5,claimants$ATTORNEY)
confusion
# Model Accuracy
Accuracy<-sum(diag(confusion)/sum(confusion))
Accuracy
Error <- 1-Accuracy
Error
# ROC Curve
library(ROCR)
rocrpred<-prediction(prob,claimants$ATTORNEY)
rocrperf<-performance(rocrpred,'tpr','fpr')
plot(rocrperf,colorize=T,text.adj=c(-0.2,1.7))
# More area under the ROC Curve better is the logistic regression model obtained
claimants <- read.csv(file.choose())
View(claimants)
# More area under the ROC Curve better is the logistic regression model obtained
install.packages("mice")
# More area under the ROC Curve better is the logistic regression model obtained
install.packages("mice")
install.packages("mice")
install.packages("markdown")
# More area under the ROC Curve better is the logistic regression model obtained
install.packages("mice")
install.packages("mice")
install.packages("mice")
install.packages("mice", dependencies = FALSE)
library(readr)
library(readxl)
install.packages("mice")
install.packages("cran")
install.packages("mice")
install.packages("MICE")
# More area under the ROC Curve better is the logistic regression model obtained
install.packages("MICE")
# More area under the ROC Curve better is the logistic regression model obtained
install.packages("MICE")
install.packages("MICE")
install.packages("mice")
install.packages("C:/Users/pc/Downloads/mice_3.7.0.tar.gz", repos = NULL, type = "source")
# ROC Curve
library(ROCR)
rocrpred<-prediction(prob,claimants$ATTORNEY)
rocrperf<-performance(rocrpred,'tpr','fpr')
plot(rocrperf,colorize=T,text.adj=c(-0.2,1.7))
# More area under the ROC Curve better is the logistic regression model obtained
library
attach(claimants)
fit1<-glm(ATTORNEY~CLMSEX+CLMINSUR+SEATBELT+CLMAGE+LOSS,data = claimants,family = "binomial")
summary(fit1)
# More area under the ROC Curve better is the logistic regression model obtained
library(mice)
install.packages("mice", dependencies = FALSE)
install.packages("D:/mice.rar", repos = NULL)
cd<- read.csv(file.choose())
View(cd)
cmd <- cd
cmd$cd <- ifelse(cmd$cd=="yes",1,0)
cmd$multi <- ifelse(cmd$multi=="yes",1,0)
cmd$premium <- ifelse(cmd$premium=="yes",1,0)
View(cmd)
cmd1 <-cmd[,-1]
mean(cmd1$price)
#Multi-Linear Regression
#Where all variables x1,x2,x3,x4,x5,x6,x7,x8,x9 and y are continous
#y-price of computer,x1,x2,x3,x4,x5,x6,x7,x8,x9 are independent variables
# Exploratory Data Analysis
summary(cmd1)
#Find the correlation b/n Output (price of computer ) & independent variables-Scatter plot
library(psych)
pairs(cmd1)
plot(cmd1)
pairs(cmd)
pairs(cmd1)
plot(cmd1)
pairs.panels(cmd1)
#Correlation coefficient
cor(cmd1)
library(corpcor)
cor2pcor(cor(cmd1))
#Model bulding
mlr <- lm(price~. ,data = cmd1)
summary(mlr)
vif(mlr)
library(caret)
library(car)
pmlr <- predict(mlr)
mean(pmlr)
RMSE(cmd1$price,pmlr)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr,id.n=2,id.cex=0.7)
qqPlot(mlr,id.n = 5)
library(dplyr)
library(data.table)
library(dummies)
library(mice)
library(markdown)
library(mnormt)
detach("package:mnormt", unload = TRUE)
library(moments)
library(NCmisc)
library(nortest)
library(openxlsx)
library(readr)
library(readxl)
library(ROCR)
library(rsconnect)
library(rmarkdown)
library(sparklyr)
library(scales)
library(tibble)
library(tidyr)
library(tidyverse)
library(VIF)
library(VIM)
library(WriteXLS)
library(xlsx)
library(MASS, lib.loc = "C:/Program Files/R/R-3.6.2/library")
library(tools, lib.loc = "C:/Program Files/R/R-3.6.2/library")
library(survival, lib.loc = "C:/Program Files/R/R-3.6.2/library")
library(parallel, lib.loc = "C:/Program Files/R/R-3.6.2/library")
library(splines, lib.loc = "C:/Program Files/R/R-3.6.2/library")
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr,id.n=2,id.cex=0.7)
qqPlot(mlr,id.n = 5)
tc<- read.csv(file.choose())
View(tc)
View(tc)
tc1 <- tc
View(tc1)
tc<- read.csv(file.choose())
View(tc)
tc1 <- tc
View(tc1)
tc2 <-tc1[,-c(1,2,5,6,8,10,11,12,15,19,20,21,21:38)]
View(tc2)
#Multi-Linear Regression
#Where all variables x1,x2,x3,x4,x5,x6,x7,x8 and y are continous
#y- predicting model price,x1,x2,x3,x4,x5,x6,x7,x8 are independent variables
# Exploratory Data Analysis
summary(tc2)
#Find the correlation b/n Output (Price of model) & independent variables-Scatter plot
library(psych)
pairs(tc2)
plot(tc2)
pairs.panels(tc2)
#Correlation coefficient
cor(tc2)
library(corpcor)
cor2pcor(cor(tc2))
#Model bulding
mlr <- lm(Price~. ,data = tc2)
summary(mlr)
# Exponential Model
mlr_exp <- lm(log(Price) ~.,data = tc2)
summary(mlr_exp)
# It is Better to delete influential observations rather than deleting entire column which is
# costliest process
# Deletion Diagnostics for identifying influential observations
influence.measures(mlr)
library(car)
## plotting Influential measures
influenceIndexPlot(mlr,id.n=3) # index plots for infuence measures
influencePlot(mlr,id.n=3) # A user friendly representation of the above
## plotting Influential measures
influenceIndexPlot(mlr,id.n=3) # index plots for infuence measures
influencePlot(mlr,id.n=3) # A user friendly representation of the above
# Regression after deleting the 81th,222th,961th observations, which is influential observation
mlr1<-lm(Price~.,data=tc2[-c(81,222,961),])
summary(mlr1)
vif(mlr1)
influenceIndexPlot(mlr1,id.n=3)
library(caret)
library(car)
pmlr <- predict(mlr1)
RMSE(tc2$Price,pmlr)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr1,id.n=2,id.cex=0.7)
qqPlot(mlr1,id.n = 5)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr,id.n=2,id.cex=0.7)
boxplot(cmd1)
plot(cmd1)
plot(cmd1)
par("mar")
par(mar=c(1,1,1,1)
pairs(cmd1)
boxplot(cmd1)
plot(cmd1)
pairs.panels(cmd1)
pairs(cmd1)
hist(cmd1)
hist(cmd1$price)
pdf('name.pdf',width = 8.267, height = 11.692)
## From above we can conclude the model is significant where P-value < 0.05 ,MR^2 is moderate
#Where RMSE value is less
pdf('name.pdf',width = 8.267, height = 11.692)
pairs(cmd1)
#Find the correlation b/n Output (price of computer ) & independent variables-Scatter plot
library(psych)
pairs(cmd1)
boxplot(cmd1)
hist(cmd1$price)
plot(cmd1)
pairs.panels(cmd1)
#Correlation coefficient
cor(cmd1)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr,id.n=2,id.cex=0.7)
qqPlot(mlr,id.n = 5)
## From above we can conclude the model is significant where P-value < 0.05 ,MR^2 is moderate
#Where RMSE value is less
pdf('name.pdf',width = 8.267, height = 11.692)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr1,id.n=2,id.cex=0.7)
qqPlot(mlr1,id.n = 5)
## From above we can conclude the mlr1 model is significant where P-value < 0.05 ,MR^2 >0.81
## From above we can conclude the mlr1 model is significant where P-value < 0.05 ,MR^2 >0.81
#Where RMSE value is less
## From above we can conclude the mlr1 model is significant where P-value < 0.05 ,MR^2 >0.81
#Where RMSE value is less
# Where we have influential values in 81th,222th,961th observations are affecting the model
## From above we can conclude the mlr1 model is significant where P-value < 0.05 ,MR^2 >0.81
#Where RMSE value is less
# Where we have influential values in 81th,222th,961th observations are affecting the model
par("mar")
qqPlot(mlr1,id.n = 5)
dev.off()
#Find the correlation b/n Output (Price of model) & independent variables-Scatter plot
library(psych)
pairs(tc2)
plot(tc2)
pairs.panels(tc2)
#Correlation coefficient
cor(tc2)
library(corpcor)
cor2pcor(cor(tc2))
#Model bulding
mlr <- lm(Price~. ,data = tc2)
summary(mlr)
# Exponential Model
mlr_exp <- lm(log(Price) ~.,data = tc2)
summary(mlr_exp)
# It is Better to delete influential observations rather than deleting entire column which is
# costliest process
# Deletion Diagnostics for identifying influential observations
influence.measures(mlr)
library(car)
## plotting Influential measures
influenceIndexPlot(mlr,id.n=3) # index plots for infuence measures
influencePlot(mlr,id.n=3) # A user friendly representation of the above
## plotting Influential measures
influenceIndexPlot(mlr,id.n=3) # index plots for infuence measures
influencePlot(mlr,id.n=3) # A user friendly representation of the above
# Regression after deleting the 81th,222th,961th observations, which is influential observation
mlr1<-lm(Price~.,data=tc2[-c(81,222,961),])
summary(mlr1)
vif(mlr1)
influenceIndexPlot(mlr1,id.n=3)
library(caret)
library(car)
pmlr <- predict(mlr1)
RMSE(tc2$Price,pmlr)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr1,id.n=2,id.cex=0.7)
qqPlot(mlr1,id.n = 5)
## From above we can conclude the mlr1 model is significant where P-value < 0.05 ,MR^2 >0.81
#Where RMSE value is less
# Where we have influential values in 81th,222th,961th observations are affecting the model
par("mar")
dev.off()
qqPlot(mlr1,id.n = 5)
dev.off()
RMSE(tc2$Price,pmlr)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr1,id.n=2,id.cex=0.7)
qqPlot(mlr1,id.n = 5)
pairs(tc2)
plot(tc2)
pairs.panels(tc2)
#Multi-Linear Regression
#Where all variables x1,x2,x3,x4,x5,x6,x7,x8,x9 and y are continous
#y-price of computer,x1,x2,x3,x4,x5,x6,x7,x8,x9 are independent variables
# Exploratory Data Analysis
summary(cmd1)
#Find the correlation b/n Output (price of computer ) & independent variables-Scatter plot
library(psych)
pairs(cmd1)
boxplot(cmd1)
hist(cmd1$price)
plot(cmd1)
pairs.panels(cmd1)
#Correlation coefficient
cor(cmd1)
library(corpcor)
cor2pcor(cor(cmd1))
#Model bulding
mlr <- lm(price~. ,data = cmd1)
summary(mlr)
vif(mlr)
vif(mlr)
library(caret)
library(car)
pmlr <- predict(mlr)
mean(pmlr)
RMSE(cmd1$price,pmlr)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr,id.n=2,id.cex=0.7)
qqPlot(mlr,id.n = 5)
vif(mlr)
sum(is.na(cmd1))
view(cmd1)
vif(mlr1)
influenceIndexPlot(mlr1,id.n=3)
library(caret)
library(car)
pmlr <- predict(mlr1)
RMSE(tc2$Price,pmlr)
## Added Variable plot to check correlation b/n variables and o/p variable
avPlots(mlr1,id.n=2,id.cex=0.7)
qqPlot(mlr1,id.n = 5)
dev.off()
plot(x50_dummy)
#Converting Discrete Column into Continous Column
str(x50)
library(dummies)
x50_dummy <- dummy.data.frame(x50,sep="_")
View(x50_dummy)
# Changing column names
View(x50_dummy)
colnames(x50_dummy)[1] <- "rd"
colnames(x50_dummy)[2] <- "ad"
colnames(x50_dummy)[3] <- "ms"
colnames(x50_dummy)[4] <- "sc"
colnames(x50_dummy)[5] <- "sf"
colnames(x50_dummy)[6] <- "sn"
colnames(x50_dummy)[7] <- "pt"
attach(x50_dummy)
library(car)
detach("package:carData", unload = TRUE)
library(carData)
library(caret)
library(corpcor)
library(data.table)
library(dbplyr)
library(dplyr)
detach("package:dbplyr", unload = TRUE)
library(dbplyr)
library(dummies)
library(markdown)
library(mice)
library(munsell)
detach("package:munsell", unload = TRUE)
library(moments)
library(NCmisc)
library(nortest)
library(openxlsx)
library(psych)
library(readr)
library(readxl)
library(rmarkdown)
library(ROCR)
library(sparklyr)
library(tibble)
library(tidyverse)
library(VIF)
library(VIM)
library(WriteXLS)
library(xlsx)
library(class, lib.loc = "C:/Program Files/R/R-3.6.2/library")
detach("package:class", unload = TRUE)
setwd("D://WORK//LOGISTIC REGRESSION")
getwd()
bd <- read.csv(file = 'bank-full.csv')
head(bd)
bd[1, ]
str(bd)
bd <- as.data.frame(read.csv(file="D://WORK//LOGISTIC REGRESSION//bank-full.csv", header=TRUE, sep=","))
view(bd)
View(bd)
bd <- as.data.frame(read.table(file="D://WORK//LOGISTIC REGRESSION//bank-full.csv", header=TRUE, sep=","))
view(bd)
str(bd)
View(bd)
bd1 <- complete(bd,1)
rlang::last_error()
bd1 <- full_join.tbl_df(full, bd, by = names(full)
view(bd1)
bd1<-as.data.frame(bd)
View(bd1)
View(bd)
library(readxl)
bank_full <- read_excel("bank-full.csv")
View(bank_full)
library(readr)
bank_full <- read_csv("bank-full.csv")
View(bank_full)
View(bank_full)
class(bank_full)
str(bank_full)
bank <- read.table("D://WORK//LOGISTIC REGRESSION//bank-full.txt",header = T,sep = ";")
view(bank)
View(bank)
bank <- read.table("D://WORK//LOGISTIC REGRESSION//bank-full.txt",header = T,sep = ",")
view(bank)
bank <- read.table("D://WORK//LOGISTIC REGRESSION//bank-full.txt",header = T,sep = ",",col(17))
view(bank)
